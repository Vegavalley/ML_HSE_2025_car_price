# Отчёт: Предсказание цен на автомобили

## 1. Проделанная работа и полученные результаты

### Этап 1: EDA
- **Визуализация**: Построили статистики числовых и категориальных признаков, попарные распределения числовых признаков (для train и test) и соответственно матрицу корреляций Пирсона. Дополнительно построили распределения зависимости цены от категориальных фич и отдельно построили распределение цены от бренда автомобиля. На основе этих графиков сделан вывод о том, какие признаки влияют на стоимость сильнее всего. И во-вторых, о том, что категориальные признаки и бренд отдельно сильно влияют на стоимость и должны присутствовать в модели.
- **Обработка**: Заполнение пропусков в данных медианой или наиболее частым жлементом, удаление torque (в связи с сложной обработкой), извлечение brand из name

### Этап 2: Модель на числовых признаках
- Были обучены различные линейные модели на числовых признаках и получены очень схожие результаты (приведу метрику R2 на тестовых данных в качестве оценки качества):
  1. Линейная регрессия: test R2:  0.5935 (результат удручающий)
  2. Линейная регрессия с стандартизацией признаков: test R2:  0.5935 (не дает заметных изменений)
  3. Лассо-регрессия с весом 1: test R2:  0.5935 (слишком малый коэффициент)
  4. Лассо-регрессия на GridSearchCV c 10 фолдами (перебрали коэффициенты [0.001, 0.01, 0.1, 1 , 10, 100, 300, 1000, 3000, 10000, 30000, 100000]): R2 на тестовом наборе: 0.5935 (Лучший коэффициент: 30000, то есть некоторые веса модель уничтожила без потери качества)
  5. ElasticNet на GridSearchCV c 10 фолдами ( 'alpha': [0.001, 0.01, 0.1, 1 , 10, 100, 300, 1000, 3000, 10000, 30000, 100000], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 1]):R2 на тестовом наборе: 0.5715 (l1_ratio=0.9,alpha = 1)
  - Добавление L2 регуляризации сказалось на результате наиболее заметным образом (в худщем смысле). Очень странным показалось, что ElasticNet не выбрала alpha=1,l1_ratio=1, так как она давала бы лучший результат на тестовой выборке. Отдельно проверила в scores. Результат действительно уступает лучшему, что может быть связано с тем, что в результате случайной инициализации фолдов сместился локальный минимум. 

### Этап 3: Добавление категориальных фич
- Сделано: One-Hot Encoding категориальных признаков (в том числе brand). Модели строились в двух конфигурациях признаков: c маркой и без нее
- Обучена Ridge с GridSearchCV (10 фолдов, 'alpha': [0.001, 0.01, 0.1, 1 , 10, 100, 300, 1000, 3000, 10000, 30000, 100000])
- Лучший результат показала модель с признаками марок: R2 на тесте: 0.7807 (alpha = 1). Результат сильно лучше, даже несмотря на то, что из-за марки признаков стало более 40

### Этап 4: Бизнесовая метрика
- Оценили наши модели с точки зрения результатов для бизнеса. Метрика: доля предсказаний с ошибкой ≤10% 
- Результаты:
  1. linear_regression: 0.2210 (22.1%)
  2. linear_regression_scaled: 0.2210 (22.1%)
  3. lasso: 0.2230 (22.3%)
  4. elasticnet: 0.2410 (24.1%)
  5. ridge_grid (с маркой): 0.3110 (31.1%)
  6. ridge_grid (без марки): 0.2440 (24.4%)
  - Лучшая модель: ridge регрессия с всеми признаками, включая марку. Таким образом, бизнес-метрика совпала в выборе модели с r2 метрикой. Интересно так же то, что elasticnet, несмотря на меньший r2 дала результат лучше, чем lasso (что говорит нам, о том, что 10% l2 регуляризация все-таки не ухудшила результат с точки зрения продукта для бизнеса)

### Этап 5: Streamlit приложение
- Собрано приложение, выдающее следующие 4 окна: предсказание по вводу, пакетное предсказание из CSV, EDA и анализ весов
- Задеплоено с streeamlit.io: https://mlhse2025carprice-n9wnntjuhnbc2rnen6svqw.streamlit.app/
- В предсказании по вводу необходимо представить модели уже предобработанные признаки (включая марку) в ограниченном диапазоне.
- В прдесказании по CSV можно загрузить test файл и получить таблицу предсказаний (визуально или в виде файла). Дополнительно указан формат вводного CSV (аналогичный тому, что мы использовали изначально. То есть предобработка включена)
- В EDA указывается какой датасет использован при обучении (статистики, распределения цен по признакам и Матрица корреляций)
- В анализе весов отрисована гистограмма топ-20 наиболее значимых признака и ниже все веса в отсортированном порядке)

## 2. Что дало наибольший результат

1. **Категориальные признаки**: +0.1 к R²
2. **Добавление марки**:+0.1 к R² (относительно модели с остальными кат. признаками)
3. **Ridge-регрессия**: не проверялась без OHE (что в принципе правильно), но мягкая L2 регуляризация явно дала неплохой результат


## 4. Что не удалось

1. **Низкая бизнес-метрика** (31.1%)
   - Причина: цены слишком сильно варьируются, некоторые признаки имеют явно нелинейное влияние

2. **Необработан torque**
   - Причина: сложный строковый формат

3. **Воспроизводимость pipeline**
   - Причина: версионные конфликты sklearn (не удалось накатить на colab совместимые версии и сделать полный пайплайн с предобработкой и моделью, streamlit.io ругался на ColumnTransformer, так как внутренние функции в версиях 1.6.1 и 1.7.2 отличались)
   - Решение: разделение на предобработку и модель: предобработка частично выполнялась прямо в streamlit, а датасет выгружен в предобработанном виде в репозиторий

## 5. Оценка сервиса

### Удобство использования:
 **Хорошо**:
- 4 вкладки с полноценным содержанием по требованиям
- Поддержка ручного ввода и CSV, отдельно можно ввести марку
- Пример CSV для скачивания

**Проблемы**:
- Нет валидации ввода и внутри ввода есть ограничения (примерно как в трейне)

### Визуализации:
✅ **Удачные**:
- Раздельные веса для числовых/категориальных признаков
- Интерактивный EDA
- Heatmap корреляций

❌ **Слабые**:
- Большие графики 
- Нет сохранения графиков
- Неудачное отображение гистограммы весов

### Ограничения:
1. плохая работа с unseen данными (можно было бы добавить более произвольный ввод данных)
2. увидела вылет приложения при загрузке большого сгенерированного csv, не нашла способ оптимизации

### Возможные улучшения:
1. Оптимизация визуальных отображений (послойная прогрузка)
2. Валидация ввода
3. Улучшение дизайна
4. Вывод статистики по предложенному CSV файлу (например, по ценам)


